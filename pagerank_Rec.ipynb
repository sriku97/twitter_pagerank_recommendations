{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26633750",
   "metadata": {},
   "source": [
    "# Personalized PageRank Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede6e376-c720-4358-ab12-828829fc366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3fdd5",
   "metadata": {},
   "source": [
    "#### Retrieve Dataset if Not Present in Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342ee526",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'https://snap.stanford.edu/data'\n",
    "filenames = [\n",
    "    # 'higgs-social_network.edgelist',\n",
    "    # 'higgs-retweet_network.edgelist',\n",
    "    'higgs-reply_network.edgelist',\n",
    "    # 'higgs-mention_network.edgelist'\n",
    "]\n",
    "\n",
    "for filename in filenames:\n",
    "    if not os.path.exists(filename):\n",
    "        # Download .gz file\n",
    "        urllib.request.urlretrieve(f'{ROOT}/{filename}.gz', f'{filename}.gz')\n",
    "\n",
    "        # Extract .edgelist file from .gz file\n",
    "        with gzip.open(f'{filename}.gz') as gzip_file:\n",
    "            with open(filename, 'wb') as edgelist_file:\n",
    "                shutil.copyfileobj(gzip_file, edgelist_file)\n",
    "        \n",
    "        # Remove .gz file\n",
    "        os.remove(f'{filename}.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86acdc4d",
   "metadata": {},
   "source": [
    "#### Personalized PageRank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e35565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalized_pagerank(G, input_node, beta=0.85, tolerance=1e-6):\n",
    "    N = len(G.nodes)\n",
    "    \n",
    "    # Assign numeric node_id to each node\n",
    "    node_ids = dict(zip(G.nodes(), np.arange(0, N)))\n",
    "    nx.set_node_attributes(G, node_ids, 'node_id')\n",
    "\n",
    "    # Generate personalization vector based on input node\n",
    "    personalization_vec = np.zeros(N)\n",
    "    personalization_vec[G.nodes[input_node]['node_id']] = 1\n",
    "\n",
    "    # Transition matrix\n",
    "    tsn_mx = np.zeros(shape=(N, N))\n",
    "    for edge in G.edges():\n",
    "        u = G.nodes[edge[0]]['node_id']\n",
    "        v = G.nodes[edge[1]]['node_id']\n",
    "        tsn_mx[v, u] = 1 / np.where(G.out_degree(edge[0]) > 0, G.out_degree(edge[0]), 1)\n",
    "\n",
    "    # Handling dangling nodes\n",
    "    row_sum = tsn_mx.sum(axis=0)\n",
    "    dangling_weights = personalization_vec\n",
    "    is_dangling = np.where(row_sum == 0)[0]\n",
    "\n",
    "    # PageRank vector, prev_pr to keep track of previous value to test convergence\n",
    "    pr = np.ones(N)\n",
    "    prev_pr = np.zeros(N)\n",
    "\n",
    "    # Iterate PageRank calculation until convergence\n",
    "    i = 0\n",
    "    while ~np.all(np.abs(pr - prev_pr) < tolerance):\n",
    "        prev_pr = pr\n",
    "        pr = beta * (np.matmul(tsn_mx, pr) + sum(pr[is_dangling]) * dangling_weights) + (1 - beta) * personalization_vec\n",
    "        pr /= np.linalg.norm(pr, ord=1)\n",
    "        i += 1\n",
    "\n",
    "    # Set PageRank values as node attributes\n",
    "    pagerank = dict(zip(G.nodes(), pr))\n",
    "    nx.set_node_attributes(G, pagerank, 'pagerank')\n",
    "\n",
    "    # Print top 20 recommendations\n",
    "    print(sorted(G.nodes(), key=lambda n: G.nodes[n]['pagerank'], reverse=True)[:20])\n",
    "\n",
    "    return pr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce9432",
   "metadata": {},
   "source": [
    "#### Twitter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58ca094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20120', '92293', '10844', '137364', '10836', '18262', '201420', '8381', '177735', '150475', '33', '4368', '196135', '93330', '194148', '142958', '11036', '195231', '327207', '38695']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 7.31360996e-17, 0.00000000e+00, ...,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve edges from dataset\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as f:\n",
    "        G.add_edges_from([tuple(edge.split(' ')[:2]) for edge in f.readlines()])\n",
    "\n",
    "personalized_pagerank(G, '20120')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b6570-a99a-44dc-842c-2c89210a47cc",
   "metadata": {},
   "source": [
    "### Test on Smaller Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be797a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 2, 5]\n",
      "[0.20778166 0.16190772 0.36365756 0.20778166 0.05887141]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.20778175890379336,\n",
       " 2: 0.16190771686152594,\n",
       " 3: 0.3636574307154471,\n",
       " 4: 0.20778175890379336,\n",
       " 5: 0.05887133461543994}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = [\n",
    "    (1, 2),\n",
    "    (2, 1),\n",
    "    (1, 3),\n",
    "    (3, 1),\n",
    "    (2, 4),\n",
    "    (3, 4),\n",
    "    (4, 3),\n",
    "    (1, 4),\n",
    "    (4, 1),\n",
    "    (2, 3),\n",
    "    (3, 2),\n",
    "    (4, 5)\n",
    "]\n",
    "\n",
    "# Compare PageRank values with NetworkX\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(edges)\n",
    "print(personalized_pagerank(G, 3))\n",
    "nx.pagerank(G, alpha=0.85, personalization={1: 0, 2: 0, 3: 1, 4: 0, 5: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fc25b-f1d0-4caa-9a57-cde90f50d420",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://github.com/networkx/networkx/blob/main/networkx/algorithms/link_analysis/pagerank_alg.py\n",
    "<br>\n",
    "https://towardsdatascience.com/pagerank-algorithm-fully-explained-dc794184b4af\n",
    "<br>\n",
    "https://www.youtube.com/watch?v=RVIr8Y5isek\n",
    "<br>\n",
    "Visualization:\n",
    "https://stellasia.github.io/blog/2020-03-07-page-rank-animation-with-networkx-numpy-and-matplotlib/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0860614780efcf110da9fdef7fce3178bfa1964cb5f7a7e94ed291ca6d1b7c50"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('jupyter_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
