{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ede6e376-c720-4358-ab12-828829fc366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22832', '20120', '92293', '13813', '4741', '3369', '7274', '2164', '7756', '18319', '310', '18262', '6644', '11339', '12389', '390301', '81', '10836', '10844', '18356']\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "with open('Pagerank/higgs-mention_network.edgelist','r') as f:\n",
    "    lines1 = f.readlines()\n",
    "\n",
    "with open('Pagerank/higgs-reply_network.edgelist','r') as f:\n",
    "    lines2 = f.readlines()\n",
    "    \n",
    "with open('Pagerank/higgs-retweet_network.edgelist','r') as f:\n",
    "    lines3 = f.readlines()\n",
    "    \n",
    "with open('Pagerank/higgs-social_network.edgelist','r') as f:\n",
    "    lines4 = f.readlines()\n",
    "    \n",
    "lines = lines1 + lines2 + lines3 + lines4\n",
    "\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "# Retrieve edges from input files\n",
    "for line in lines:\n",
    "    edges.append(tuple(line.split(' ')[:2]))\n",
    "\n",
    "# Retrieve nodes from edges\n",
    "nodes = set(itertools.chain(*edges))\n",
    "count_nodes = len(nodes)\n",
    "\n",
    "# Assign numeric node id to each node\n",
    "node_ids = dict(zip(nodes,np.arange(0,count_nodes)))\n",
    "\n",
    "# Create networkx graph\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "nx.set_node_attributes(G, node_ids, \"node_id\")\n",
    "\n",
    "# Node for which recommendations are generated\n",
    "input_node = '20120'\n",
    "\n",
    "# Generate personalization vector based on input node\n",
    "personalization_vec = np.zeros(count_nodes)\n",
    "personalization_vec[G.nodes[input_node]['node_id']] = 1\n",
    "\n",
    "# Transition matrix\n",
    "tsn_mx = np.zeros(shape=(count_nodes,count_nodes))\n",
    "for e in G.edges():\n",
    "    tsn_mx[G.nodes[e[1]]['node_id'], G.nodes[e[0]]['node_id']] = 1/np.where(G.out_degree(e[0]) > 0, G.out_degree(e[0]), 1)\n",
    "\n",
    "# Handling dangling nodes \n",
    "row_sum = tsn_mx.sum(axis=0)\n",
    "dangling_weights = personalization_vec\n",
    "is_dangling = np.where(row_sum == 0)[0]\n",
    "    \n",
    "# Pagerank vector, prev_pr to keep track of previous value to test convergence\n",
    "pr = np.ones(count_nodes)\n",
    "prev_pr = np.zeros(count_nodes)\n",
    "\n",
    "beta = 0.85\n",
    "tolerance = 1e-6\n",
    "\n",
    "# Iterate pagerank calculation until convergence\n",
    "while ~np.all(np.abs(pr-prev_pr) < tolerance):\n",
    "    prev_pr = pr\n",
    "    pr = beta*(np.matmul(tsn_mx,pr) + sum(pr[is_dangling])*dangling_weights) + (1-beta)*personalization_vec\n",
    "    pr = pr/np.linalg.norm(pr,ord=1)\n",
    "\n",
    "# Set pagerank values as node attributes\n",
    "pagerank = dict(zip(list(node_ids.keys()),pr))\n",
    "nx.set_node_attributes(G, pagerank, \"pagerank\")\n",
    "\n",
    "# Print top 20 recommendations\n",
    "print(sorted(G.nodes(), key=lambda n: G.nodes[n]['pagerank'],reverse=True)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fc25b-f1d0-4caa-9a57-cde90f50d420",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://github.com/networkx/networkx/blob/main/networkx/algorithms/link_analysis/pagerank_alg.py\n",
    "<br>\n",
    "https://towardsdatascience.com/pagerank-algorithm-fully-explained-dc794184b4af\n",
    "<br>\n",
    "https://www.youtube.com/watch?v=RVIr8Y5isek\n",
    "<br>\n",
    "Visualization\n",
    "https://stellasia.github.io/blog/2020-03-07-page-rank-animation-with-networkx-numpy-and-matplotlib/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b6570-a99a-44dc-842c-2c89210a47cc",
   "metadata": {},
   "source": [
    "### Testing on smaller graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c8abf8f-aab2-40c0-a649-f7d9d50b7386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20778166 0.16190772 0.36365756 0.20778166 0.05887141]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.20778175890379338,\n",
       " 2: 0.16190771686152597,\n",
       " 3: 0.36365743071544715,\n",
       " 4: 0.2077817589037934,\n",
       " 5: 0.05887133461543995}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_node(1)\n",
    "G.add_node(2)\n",
    "G.add_node(3)\n",
    "G.add_node(4)\n",
    "G.add_node(5)\n",
    "G.add_edge(1,2)\n",
    "G.add_edge(2,1)\n",
    "G.add_edge(1,3)\n",
    "G.add_edge(3,1)\n",
    "G.add_edge(2,4)\n",
    "G.add_edge(3,4)\n",
    "G.add_edge(4,3)\n",
    "G.add_edge(1,4)\n",
    "G.add_edge(4,1)\n",
    "G.add_edge(4,1)\n",
    "G.add_edge(2,3)\n",
    "G.add_edge(3,2)\n",
    "G.add_edge(4,5)\n",
    "\n",
    "nodes = {1,2,3,4,5}\n",
    "count_nodes = len(nodes)\n",
    "\n",
    "node_ids = dict(zip(nodes,np.arange(0,count_nodes)))\n",
    "\n",
    "nx.set_node_attributes(G, node_ids, \"node_id\")\n",
    "\n",
    "input_node = 3\n",
    "personalization_vec = np.zeros(count_nodes)\n",
    "personalization_vec[G.nodes[input_node]['node_id']] = 1\n",
    "\n",
    "\n",
    "tsn_mx = np.zeros(shape=(count_nodes,count_nodes))\n",
    "for e in G.edges():\n",
    "    tsn_mx[G.nodes[e[1]]['node_id'], G.nodes[e[0]]['node_id']] = 1/np.where(G.out_degree(e[0]) > 0, G.out_degree(e[0]), 1)\n",
    "\n",
    "\n",
    "s = tsn_mx.sum(axis=0)\n",
    "dw = personalization_vec\n",
    "is_dangling = np.where(s == 0)[0]\n",
    "\n",
    "\n",
    "pr = np.ones(5)\n",
    "prev_pr = np.zeros(5)\n",
    "i=0\n",
    "while ~np.all(np.abs(pr-prev_pr) < 1e-6):\n",
    "    prev_pr = pr\n",
    "    pr = 0.85*(np.matmul(tsn_mx,pr) + sum(pr[is_dangling]) * dw) + 0.15*personalization_vec\n",
    "    pr = pr/np.linalg.norm(pr,ord=1)\n",
    "    i=i+1\n",
    "print(pr/np.linalg.norm(pr,ord=1))\n",
    "\n",
    "nx.pagerank(G,alpha=0.85,personalization={1:0,2:0,3:1,4:0,5:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9f4f5-3d24-458c-8db7-db76e21ed500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4345a-86c7-4a4f-b0a8-c5a4114125ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
